{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-184b3c447b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./train.csv\"\n",
    "test_file = \"./test.csv\"\n",
    "num_cols = [\"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\"]\n",
    "ignore_cols = [\"id\", \"target\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \n",
    "               \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \n",
    "               \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\",\"ps_calc_15_bin\", \"ps_calc_16_bin\", \n",
    "               \"ps_calc_17_bin\",\"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"feature_size\": None,\n",
    "    \"field_size\": None,\n",
    "    \"embed_size\": 128,\n",
    "    \"deep_nn\":[256,256],\n",
    "    \"dropout_fm\": 0,\n",
    "    \"dropout_deep\": 0.2,\n",
    "    \"output_bias\": None,\n",
    "    \"epoch\": 200,\n",
    "    \"batch\":10000,\n",
    "    \"split\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(cfg):    \n",
    "    dfTrain = pd.read_csv(train_file)\n",
    "    dfTest = pd.read_csv(test_file)\n",
    "    df = pd.concat([dfTrain,dfTest], sort=False)\n",
    "\n",
    "    field_size = len(df.columns) - len(ignore_cols)\n",
    "    feature_dict = {}\n",
    "    feature_size = 0\n",
    "    for col in df.columns:\n",
    "        if col in ignore_cols:\n",
    "            continue\n",
    "        elif col in num_cols:\n",
    "            feature_dict[col] = feature_size\n",
    "            feature_size += 1\n",
    "        else:\n",
    "            unique_val = df[col].unique()\n",
    "            feature_dict[col] = dict(zip(unique_val,range(feature_size,len(unique_val) + feature_size)))\n",
    "            feature_size += len(unique_val)\n",
    "    \n",
    "    cfg['field_size'] = field_size\n",
    "    cfg['feature_size'] = feature_size\n",
    "    return dfTrain, feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain, feature_dict = overview(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, feature_dict, cfg):\n",
    "    label_df = train_df[['target']]  \n",
    "    neg, pos = np.bincount(label_df.values.flatten())\n",
    "    cfg['output_bias'] = np.log([pos/neg])\n",
    "    train_df.drop(['target','id'],axis=1,inplace=True)\n",
    "    feature_idx = train_df.copy()\n",
    "    feature_val = train_df.copy()\n",
    "    for col in feature_idx.columns:\n",
    "        if col in ignore_cols:\n",
    "            feature_idx.drop(col,axis=1,inplace=True)\n",
    "            feature_val.drop(col,axis=1,inplace=True)\n",
    "            continue\n",
    "        elif col in num_cols:\n",
    "            feature_idx[col] = feature_dict[col]\n",
    "        else:\n",
    "            feature_idx[col] = feature_idx[col].map(feature_dict[col])\n",
    "            feature_val[col] = 1      \n",
    "            \n",
    "    train_idx_df, test_idx_df = train_test_split(feature_idx, test_size=cfg[\"split\"])\n",
    "    train_val_df, test_val_df = train_test_split(feature_val, test_size=cfg[\"split\"])\n",
    "    train_label_df, test_label_df = train_test_split(label_df, test_size=cfg[\"split\"])\n",
    "    \n",
    "    train_idx_df, validate_idx_df = train_test_split(train_idx_df, test_size=cfg[\"split\"])\n",
    "    train_val_df, validate_val_df = train_test_split(train_val_df, test_size=cfg[\"split\"])\n",
    "    train_label_df, validate_label_df = train_test_split(train_label_df, test_size=cfg[\"split\"])\n",
    "    \n",
    "    train_input = [train_idx_df.values, train_val_df.values]\n",
    "    train_label = np.array(train_label_df['target'])\n",
    "    bool_train_labels = train_label != 0\n",
    "    \n",
    "    validate_input = [validate_idx_df.values, validate_val_df.values]\n",
    "    validate_label = validate_label_df.values\n",
    "    \n",
    "    test_input = [test_idx_df.values, test_val_df.values]\n",
    "    test_label = test_label_df.values\n",
    "    \n",
    "    return train_input, train_label, bool_train_labels, validate_input, validate_label, test_input, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_label, bool_train_labels, validate_input, validate_label, test_input, test_label = preprocess(dfTrain, feature_dict, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(train_input, train_label, bool_train_labels):\n",
    "    pos_idx = train_input[0][bool_train_labels]\n",
    "    neg_idx = train_input[0][~bool_train_labels]\n",
    "    pos_val = train_input[1][bool_train_labels]\n",
    "    neg_val = train_input[1][~bool_train_labels]\n",
    "    pos_label = train_label[bool_train_labels]\n",
    "    neg_label = train_label[~bool_train_labels]\n",
    "    \n",
    "    ids = np.arange(len(pos_idx))\n",
    "    choices = np.random.choice(ids, len(neg_idx))\n",
    "    \n",
    "    res_pos_idx = pos_idx[choices]\n",
    "    res_pos_val = pos_val[choices]\n",
    "    res_pos_label = pos_label[choices]\n",
    "    \n",
    "    resampled_idx = np.concatenate([res_pos_idx, neg_idx], axis=0)\n",
    "    resampled_val = np.concatenate([res_pos_val, neg_val], axis=0)\n",
    "    resampled_label = np.concatenate([res_pos_label, neg_label], axis=0)\n",
    "\n",
    "    order = np.arange(len(resampled_label))\n",
    "    np.random.shuffle(order)    \n",
    "    return [resampled_idx[order], resampled_val[order]], resampled_label[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train_input, res_train_label = oversample(train_input, train_label, bool_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(tf.keras.Model):\n",
    "    def __init__(self, cfg):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.feature_size = cfg['feature_size']\n",
    "        self.field_size = cfg['field_size']\n",
    "        self.embed_size = cfg['embed_size']\n",
    "        self.deep_nn = cfg['deep_nn']\n",
    "        \n",
    "        self.dropout_fm = cfg['dropout_fm']\n",
    "        self.dropout_deep = cfg['dropout_deep']\n",
    "        \n",
    "        # fm        \n",
    "        self.feature_weight = tf.keras.layers.Embedding(cfg['feature_size'], 1)\n",
    "        self.feature_embed = tf.keras.layers.Embedding(cfg['feature_size'], cfg['embed_size'])\n",
    "\n",
    "        # dnn\n",
    "        for layer in range(len(cfg['deep_nn'])):\n",
    "            setattr(self, 'dense_' + str(layer), tf.keras.layers.Dense(self.deep_nn[layer]))\n",
    "            setattr(self, 'batchNorm_' + str(layer), tf.keras.layers.BatchNormalization())\n",
    "            setattr(self, 'activation_' + str(layer), tf.keras.layers.Activation('relu'))\n",
    "            setattr(self, 'dropout_' + str(layer), tf.keras.layers.Dropout(self.dropout_deep))\n",
    "            \n",
    "        self.fc = tf.keras.layers.Dense(1, activation='sigmoid', \n",
    "                                        bias_initializer=tf.keras.initializers.Constant(cfg['output_bias']))\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # inputs = [feature_idx, feature_val]\n",
    "        reshaped_feature_val = tf.cast(tf.reshape(inputs[1], shape=[-1,self.field_size,1]), tf.float32)\n",
    "        # linear        \n",
    "        weights = self.feature_weight(inputs[0])\n",
    "        linear = tf.reduce_sum(tf.multiply(weights,reshaped_feature_val),2)\n",
    "        \n",
    "        # fm  \n",
    "        embeddings = self.feature_embed(inputs[0])\n",
    "        second_inner = tf.multiply(embeddings,reshaped_feature_val)\n",
    "        \n",
    "        summed_features_emb = tf.reduce_sum(second_inner,1)\n",
    "        summed_features_emb_square = tf.square(summed_features_emb)\n",
    "        \n",
    "        squared_features_emb = tf.square(second_inner)\n",
    "        squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "        \n",
    "        fm = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "        \n",
    "        # dnn\n",
    "        y_deep = tf.reshape(embeddings,shape=[-1,self.field_size * self.embed_size])\n",
    "        for layer in range(0, len(self.deep_nn)):\n",
    "            y_deep = getattr(self, 'dense_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'batchNorm_' + str(layer))(y_deep, training=training)\n",
    "            y_deep = getattr(self, 'activation_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'dropout_' + str(layer))(y_deep, training=training)\n",
    "            \n",
    "        # concat\n",
    "        concat = tf.concat([linear, fm, y_deep], axis=1)                                \n",
    "        out = self.fc(concat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', verbose=1, patience=10, mode='max',restore_best_weights=True)\n",
    "metrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "           tf.keras.metrics.FalsePositives(name='fp'),\n",
    "           tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "           tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "           tf.keras.metrics.BinaryAccuracy(name='bin_acc'),\n",
    "           tf.keras.metrics.Precision(name='precision'),\n",
    "           tf.keras.metrics.Recall(name='recall'),\n",
    "           tf.keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 733922 samples, validate on 95234 samples\n",
      "Epoch 1/200\n",
      "733922/733922 [==============================] - 11s 15us/sample - loss: 0.6895 - tp: 14672.0000 - fp: 6103.0000 - tn: 360858.0000 - fn: 352289.0000 - bin_acc: 0.5117 - precision: 0.7062 - recall: 0.0400 - auc: 0.5440 - val_loss: 0.7085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 91768.0000 - val_fn: 3466.0000 - val_bin_acc: 0.9636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5056\n",
      "Epoch 2/200\n",
      "733922/733922 [==============================] - 8s 11us/sample - loss: 0.6782 - tp: 62499.0000 - fp: 21451.0000 - tn: 345510.0000 - fn: 304462.0000 - bin_acc: 0.5559 - precision: 0.7445 - recall: 0.1703 - auc: 0.5896 - val_loss: 0.7295 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 91768.0000 - val_fn: 3466.0000 - val_bin_acc: 0.9636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5088\n",
      "Epoch 3/200\n",
      "733922/733922 [==============================] - 10s 13us/sample - loss: 0.6680 - tp: 94909.0000 - fp: 28826.0000 - tn: 338135.0000 - fn: 272052.0000 - bin_acc: 0.5900 - precision: 0.7670 - recall: 0.2586 - auc: 0.6188 - val_loss: 0.8028 - val_tp: 290.0000 - val_fp: 7396.0000 - val_tn: 84372.0000 - val_fn: 3176.0000 - val_bin_acc: 0.8890 - val_precision: 0.0377 - val_recall: 0.0837 - val_auc: 0.5090\n",
      "Epoch 4/200\n",
      "733922/733922 [==============================] - 9s 13us/sample - loss: 0.6604 - tp: 113336.0000 - fp: 30807.0000 - tn: 336154.0000 - fn: 253625.0000 - bin_acc: 0.6124 - precision: 0.7863 - recall: 0.3089 - auc: 0.6388 - val_loss: 0.7696 - val_tp: 306.0000 - val_fp: 8010.0000 - val_tn: 83758.0000 - val_fn: 3160.0000 - val_bin_acc: 0.8827 - val_precision: 0.0368 - val_recall: 0.0883 - val_auc: 0.5103\n",
      "Epoch 5/200\n",
      "733922/733922 [==============================] - 10s 13us/sample - loss: 0.6545 - tp: 126750.0000 - fp: 31905.0000 - tn: 335056.0000 - fn: 240211.0000 - bin_acc: 0.6292 - precision: 0.7989 - recall: 0.3454 - auc: 0.6548 - val_loss: 0.8001 - val_tp: 605.0000 - val_fp: 15421.0000 - val_tn: 76347.0000 - val_fn: 2861.0000 - val_bin_acc: 0.8080 - val_precision: 0.0378 - val_recall: 0.1746 - val_auc: 0.5065\n",
      "Epoch 6/200\n",
      "733922/733922 [==============================] - 9s 13us/sample - loss: 0.6494 - tp: 137561.0000 - fp: 32387.0000 - tn: 334574.0000 - fn: 229400.0000 - bin_acc: 0.6433 - precision: 0.8094 - recall: 0.3749 - auc: 0.6688 - val_loss: 0.7508 - val_tp: 312.0000 - val_fp: 8114.0000 - val_tn: 83654.0000 - val_fn: 3154.0000 - val_bin_acc: 0.8817 - val_precision: 0.0370 - val_recall: 0.0900 - val_auc: 0.5079\n",
      "Epoch 7/200\n",
      "733922/733922 [==============================] - 10s 13us/sample - loss: 0.6448 - tp: 146461.0000 - fp: 32181.0000 - tn: 334780.0000 - fn: 220500.0000 - bin_acc: 0.6557 - precision: 0.8199 - recall: 0.3991 - auc: 0.6813 - val_loss: 0.7317 - val_tp: 209.0000 - val_fp: 5489.0000 - val_tn: 86279.0000 - val_fn: 3257.0000 - val_bin_acc: 0.9082 - val_precision: 0.0367 - val_recall: 0.0603 - val_auc: 0.5013\n",
      "Epoch 8/200\n",
      "733922/733922 [==============================] - 9s 12us/sample - loss: 0.6408 - tp: 154043.0000 - fp: 31943.0000 - tn: 335018.0000 - fn: 212918.0000 - bin_acc: 0.6664 - precision: 0.8283 - recall: 0.4198 - auc: 0.6919 - val_loss: 0.7700 - val_tp: 478.0000 - val_fp: 11760.0000 - val_tn: 80008.0000 - val_fn: 2988.0000 - val_bin_acc: 0.8451 - val_precision: 0.0391 - val_recall: 0.1379 - val_auc: 0.5021\n",
      "Epoch 9/200\n",
      "733922/733922 [==============================] - 9s 12us/sample - loss: 0.6377 - tp: 160731.0000 - fp: 32388.0000 - tn: 334573.0000 - fn: 206230.0000 - bin_acc: 0.6749 - precision: 0.8323 - recall: 0.4380 - auc: 0.7007 - val_loss: 0.7505 - val_tp: 328.0000 - val_fp: 8717.0000 - val_tn: 83051.0000 - val_fn: 3138.0000 - val_bin_acc: 0.8755 - val_precision: 0.0363 - val_recall: 0.0946 - val_auc: 0.5033\n",
      "Epoch 10/200\n",
      "733922/733922 [==============================] - 9s 12us/sample - loss: 0.6343 - tp: 167123.0000 - fp: 32140.0000 - tn: 334821.0000 - fn: 199838.0000 - bin_acc: 0.6839 - precision: 0.8387 - recall: 0.4554 - auc: 0.7090 - val_loss: 0.7535 - val_tp: 367.0000 - val_fp: 9225.0000 - val_tn: 82543.0000 - val_fn: 3099.0000 - val_bin_acc: 0.8706 - val_precision: 0.0383 - val_recall: 0.1059 - val_auc: 0.5068\n",
      "Epoch 11/200\n",
      "733922/733922 [==============================] - 10s 13us/sample - loss: 0.6318 - tp: 171052.0000 - fp: 31560.0000 - tn: 335401.0000 - fn: 195909.0000 - bin_acc: 0.6901 - precision: 0.8442 - recall: 0.4661 - auc: 0.7162 - val_loss: 0.7908 - val_tp: 637.0000 - val_fp: 15217.0000 - val_tn: 76551.0000 - val_fn: 2829.0000 - val_bin_acc: 0.8105 - val_precision: 0.0402 - val_recall: 0.1838 - val_auc: 0.5054\n",
      "Epoch 12/200\n",
      "733922/733922 [==============================] - 9s 12us/sample - loss: 0.6292 - tp: 175870.0000 - fp: 31335.0000 - tn: 335626.0000 - fn: 191091.0000 - bin_acc: 0.6969 - precision: 0.8488 - recall: 0.4793 - auc: 0.7231 - val_loss: 0.7843 - val_tp: 553.0000 - val_fp: 14258.0000 - val_tn: 77510.0000 - val_fn: 2913.0000 - val_bin_acc: 0.8197 - val_precision: 0.0373 - val_recall: 0.1595 - val_auc: 0.5068\n",
      "Epoch 13/200\n",
      "733922/733922 [==============================] - 9s 12us/sample - loss: 0.6263 - tp: 181348.0000 - fp: 31068.0000 - tn: 335893.0000 - fn: 185613.0000 - bin_acc: 0.7048 - precision: 0.8537 - recall: 0.4942 - auc: 0.7304 - val_loss: 0.7593 - val_tp: 399.0000 - val_fp: 10290.0000 - val_tn: 81478.0000 - val_fn: 3067.0000 - val_bin_acc: 0.8597 - val_precision: 0.0373 - val_recall: 0.1151 - val_auc: 0.5046\n",
      "Epoch 14/200\n",
      "730000/733922 [============================>.] - ETA: 0s - loss: 0.6242 - tp: 183181.0000 - fp: 30248.0000 - tn: 334749.0000 - fn: 181822.0000 - bin_acc: 0.7095 - precision: 0.8583 - recall: 0.5019 - auc: 0.7359Restoring model weights from the end of the best epoch.\n",
      "733922/733922 [==============================] - 9s 13us/sample - loss: 0.6242 - tp: 184192.0000 - fp: 30423.0000 - tn: 336538.0000 - fn: 182769.0000 - bin_acc: 0.7095 - precision: 0.8582 - recall: 0.5019 - auc: 0.7359 - val_loss: 0.7289 - val_tp: 205.0000 - val_fp: 5392.0000 - val_tn: 86376.0000 - val_fn: 3261.0000 - val_bin_acc: 0.9091 - val_precision: 0.0366 - val_recall: 0.0591 - val_auc: 0.5030\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e83d13d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepFM(cfg)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr=1e-3), \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              metrics=metrics)\n",
    "model.fit(res_train_input, res_train_label, epochs=cfg['epoch'], batch_size=cfg['batch'], shuffle=True, \n",
    "          verbose=1, callbacks = [early_stopping], validation_data=(validate_input, validate_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('base_pramas.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os \n",
    "path = 'init_params'\n",
    "os.mkdir(path)\n",
    "model.save_weights(path+'/weights', overwrite=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = DeepFM(cfg)\n",
    "model.load_weights('init_params/weights')\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr=1e-3), \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              metrics=metrics)\n",
    "model.fit(res_train_input, res_train_label, epochs=cfg['epoch'], batch_size=cfg['batch'], shuffle=True, \n",
    "          verbose=1, callbacks = [early_stopping], validation_data=(validate_input, validate_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_fm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  257       \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1212672   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  422       \n",
      "=================================================================\n",
      "Total params: 1,314,087\n",
      "Trainable params: 1,313,063\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wei/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodemo = tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_fm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You tried to call `count_params` on embedding, but the layer isn't built. You can build it manually via: `embedding.build(batch_input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a1d96f117a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemodemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1263\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                               print_fn=print_fn)\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m       \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1627\u001b[0m                          \u001b[0;34m', but the layer isn\\'t built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m                          \u001b[0;34m'You can build it manually via: `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[1;32m   1630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You tried to call `count_params` on embedding, but the layer isn't built. You can build it manually via: `embedding.build(batch_input_shape)`."
     ]
    }
   ],
   "source": [
    "demodemo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
