{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./train.csv\"\n",
    "test_file = \"./test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(train_file)\n",
    "dfTest = pd.read_csv(test_file)\n",
    "df = pd.concat([dfTrain,dfTest], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "    \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\"\n",
    "]\n",
    "\n",
    "ignore_cols = [\n",
    "    \"id\", \"target\",\n",
    "    \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\",\n",
    "    \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\",\n",
    "    \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\",\n",
    "    \"ps_calc_13\", \"ps_calc_14\",\n",
    "    \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\",\n",
    "    \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "total_feature = 0\n",
    "for col in df.columns:\n",
    "    if col in ignore_cols:\n",
    "        continue\n",
    "    elif col in num_cols:\n",
    "        feature_dict[col] = total_feature\n",
    "        total_feature += 1\n",
    "    else:\n",
    "        unique_val = df[col].unique()\n",
    "        feature_dict[col] = dict(zip(unique_val,range(total_feature,len(unique_val) + total_feature)))\n",
    "        total_feature += len(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = dfTrain[['target']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain.drop(['target','id'],axis=1,inplace=True)\n",
    "train_feature_index = dfTrain.copy()\n",
    "train_feature_value = dfTrain.copy()\n",
    "\n",
    "for col in train_feature_index.columns:\n",
    "    if col in ignore_cols:\n",
    "        train_feature_index.drop(col,axis=1,inplace=True)\n",
    "        train_feature_value.drop(col,axis=1,inplace=True)\n",
    "        continue\n",
    "    elif col in num_cols:\n",
    "        train_feature_index[col] = feature_dict[col]\n",
    "    else:\n",
    "        train_feature_index[col] = train_feature_index[col].map(feature_dict[col])\n",
    "        train_feature_value[col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>133</td>\n",
       "      <td>135</td>\n",
       "      <td>141</td>\n",
       "      <td>144</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>141</td>\n",
       "      <td>147</td>\n",
       "      <td>250</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>148</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>141</td>\n",
       "      <td>180</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>228</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>180</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>154</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>141</td>\n",
       "      <td>181</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0               0              8         13             25             28   \n",
       "1               1              9         14             26             28   \n",
       "2               2             10         15             25             28   \n",
       "3               3              9         16             26             28   \n",
       "4               3              8         17             25             28   \n",
       "...           ...            ...        ...            ...            ...   \n",
       "595207          5              9         24             26             28   \n",
       "595208          2              9         19             26             28   \n",
       "595209          1              9         24             26             28   \n",
       "595210          2              8         19             25             28   \n",
       "595211          3              9         23             26             28   \n",
       "\n",
       "        ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "0                  36             38             40             42   \n",
       "1                  36             39             41             42   \n",
       "2                  36             39             41             42   \n",
       "3                  37             39             40             42   \n",
       "4                  37             39             40             42   \n",
       "...               ...            ...            ...            ...   \n",
       "595207             36             39             40             43   \n",
       "595208             36             39             40             43   \n",
       "595209             37             39             40             42   \n",
       "595210             36             39             41             42   \n",
       "595211             37             39             40             42   \n",
       "\n",
       "        ps_ind_10_bin  ...  ps_car_07_cat  ps_car_08_cat  ps_car_09_cat  \\\n",
       "0                  44  ...            130            133            135   \n",
       "1                  44  ...            130            134            136   \n",
       "2                  44  ...            130            134            136   \n",
       "3                  44  ...            130            134            137   \n",
       "4                  44  ...            130            134            136   \n",
       "...               ...  ...            ...            ...            ...   \n",
       "595207             44  ...            130            134            135   \n",
       "595208             44  ...            132            133            136   \n",
       "595209             44  ...            130            134            136   \n",
       "595210             44  ...            130            134            136   \n",
       "595211             44  ...            130            133            136   \n",
       "\n",
       "        ps_car_10_cat  ps_car_11_cat  ps_car_11  ps_car_12  ps_car_13  \\\n",
       "0                 141            144        248        253        254   \n",
       "1                 141            145        249        253        254   \n",
       "2                 141            146        250        253        254   \n",
       "3                 141            147        250        253        254   \n",
       "4                 141            148        249        253        254   \n",
       "...               ...            ...        ...        ...        ...   \n",
       "595207            141            180        249        253        254   \n",
       "595208            141            228        248        253        254   \n",
       "595209            141            180        249        253        254   \n",
       "595210            141            154        249        253        254   \n",
       "595211            141            181        248        253        254   \n",
       "\n",
       "        ps_car_14  ps_car_15  \n",
       "0             255        256  \n",
       "1             255        256  \n",
       "2             255        256  \n",
       "3             255        256  \n",
       "4             255        256  \n",
       "...           ...        ...  \n",
       "595207        255        256  \n",
       "595208        255        256  \n",
       "595209        255        256  \n",
       "595210        255        256  \n",
       "595211        255        256  \n",
       "\n",
       "[595212 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feature_index.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_params = {\n",
    "    \"use_fm\":True,\n",
    "    \"use_deep\":True,\n",
    "    \"embedding_size\":8,\n",
    "    \"dropout_fm\":[1.0,1.0],\n",
    "    \"deep_layers\":[32,32],\n",
    "    \"dropout_deep\":[0.5,0.5,0.5],\n",
    "    \"deep_layer_activation\":tf.nn.relu,\n",
    "    \"epoch\":30,\n",
    "    \"batch_size\":1024,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"batch_norm\":1,\n",
    "    \"batch_norm_decay\":0.995,\n",
    "    \"l2_reg\":0.01,\n",
    "    \"verbose\":True,\n",
    "    \"eval_metric\":'gini_norm',\n",
    "    \"random_seed\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_params['feature_size'] = total_feature\n",
    "dfm_params['field_size'] = len(train_feature_index.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict()\n",
    "weights['feature_embeddings'] = tf.Variable(tf.random.normal(shape=[dfm_params['feature_size'], dfm_params['embedding_size']], mean=0.0, stddev=0.01))\n",
    "weights['feature_bias'] = tf.Variable(tf.random.normal(shape=[dfm_params['feature_size'], 1], mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_index = tf.constant(train_feature_index[:3].values)\n",
    "demo_val = tf.constant(train_feature_value[:3].values, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 37, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_demo_val = tf.reshape(demo_val, shape=[-1,dfm_params['field_size'],1])\n",
    "reshaped_demo_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 37, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_order = tf.nn.embedding_lookup(weights['feature_bias'],demo_index)\n",
    "first_order.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 37])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_first_order = tf.reduce_sum(tf.multiply(first_order,reshaped_demo_val),2)\n",
    "fm_first_order.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 37, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = tf.nn.embedding_lookup(weights['feature_embeddings'],demo_index)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_inner = tf.multiply(embeddings,reshaped_demo_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_features_emb = tf.reduce_sum(second_inner,1)\n",
    "summed_features_emb_square = tf.square(summed_features_emb)\n",
    "summed_features_emb_square.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_features_emb = tf.square(second_inner)\n",
    "squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "squared_sum_features_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_second_order = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "fm_second_order.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_weight = dict()\n",
    "nn_bias = dict()\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "y_deep = tf.reshape(embeddings,shape=[-1,dfm_params['field_size'] * dfm_params['embedding_size']])\n",
    "for layer in range(0, len(dfm_params['deep_layers'])):\n",
    "    if layer==0:\n",
    "        input_size = dfm_params['field_size'] * dfm_params['embedding_size']\n",
    "        nn_weight[layer] = tf.Variable(initializer([input_size, dfm_params['deep_layers'][0]]))\n",
    "    else:\n",
    "        nn_weight[layer] = tf.Variable(initializer([dfm_params['deep_layers'][layer-1], dfm_params['deep_layers'][layer]]))\n",
    "\n",
    "    nn_bias[layer] = tf.Variable(initializer([1, dfm_params['deep_layers'][layer]]))\n",
    "    y_deep = tf.add(tf.matmul(y_deep,nn_weight[layer]), nn_bias[layer])\n",
    "    y_deep = tf.nn.relu(y_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_deep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.concat([fm_first_order,fm_second_order,y_deep],axis=1)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 77])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_weight=dict()\n",
    "concat_weight['projection']=tf.Variable(initializer([concat.shape[1], 1]))\n",
    "concat_weight['bias']=tf.Variable(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.sigmoid(tf.add(tf.matmul(concat,concat_weight['projection']),concat_weight['bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=131, shape=(3, 1), dtype=float32, numpy=\n",
       "array([[0.48425516],\n",
       "       [0.4848058 ],\n",
       "       [0.48494187]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.feature_size = cfg['feature_size']\n",
    "        self.field_size = cfg['field_size']\n",
    "        self.embed_size = cfg['embed_size']\n",
    "        self.deep_nn = cfg['deep_nn']\n",
    "        \n",
    "        # fm        \n",
    "        self.feature_weight = tf.keras.layers.Embedding(cfg['feature_size'], 1)\n",
    "        self.feature_embed = tf.keras.layers.Embedding(cfg['field_size'], cfg['embed_size'])\n",
    "\n",
    "        # dnn\n",
    "        for layer in range(len(cfg['deep_nn'])):\n",
    "            setattr(self, 'dense_' + str(layer), tf.keras.layers.Dense(self.deep_nn[layer]))\n",
    "            setattr(self, 'batchNorm_' + str(layer), tf.keras.layers.BatchNormalization())\n",
    "            setattr(self, 'activation_' + str(layer), tf.keras.layers.Activation('relu'))\n",
    "            setattr(self, 'dropout_' + str(layer), tf.keras.layers.Dropout(dropout_deep))\n",
    "            \n",
    "        self.fc = tf.keras.layers.Dense(1, activation='sigmoid', use_bias=True)\n",
    "\n",
    "    def call(self, feature_idx, feature_val):\n",
    "        reshaped_feature_val = tf.reshape(feature_val, shape=[-1,self.field_size,1])\n",
    "        # linear        \n",
    "        weights　＝　self.feature_weight(feature_idx)\n",
    "        linear = tf.reduce_sum(tf.multiply(weights,reshaped_feature_val),2)\n",
    "        \n",
    "        # fm  \n",
    "        embeddings = self.feature_embed(feature_idx)\n",
    "        second_inner = tf.multiply(embeddings,reshaped_feature_val)\n",
    "        \n",
    "        summed_features_emb = tf.reduce_sum(second_inner,1)\n",
    "        summed_features_emb_square = tf.square(summed_features_emb)\n",
    "        \n",
    "        squared_features_emb = tf.square(second_inner)\n",
    "        squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "        \n",
    "        fm = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "        \n",
    "        # dnn\n",
    "        y_deep = tf.reshape(embeddings,shape=[-1,self.field_size * self.embed_size])\n",
    "        for layer in range(0, len(self.deep_nn)):\n",
    "            y_deep = getattr(self, 'dense_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'batchNorm_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'activation_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'dropout_' + str(layer))(y_deep)\n",
    "            \n",
    "        # concat\n",
    "        concat = tf.concat([linear, fm, y_deep], axis=1)                                \n",
    "        out = self.fc(concat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_idx, x_val, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_ = model(x_idx, x_val)\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        loss = bce(y_true=y, y_pred=y_)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    print(\"train loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_index = tf.constant(train_feature_index[:3].values)\n",
    "demo_val = tf.constant(train_feature_value[:3].values, dtype=tf.float32)\n",
    "demo_label = train_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"feature_size\": total_feature,\n",
    "    \"field_size\": len(train_feature_index.columns),\n",
    "    \"embed_size\":8,\n",
    "    \"deep_nn\":[32,32]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(cfg)\n",
    "train_model(model, demo_index, demo_val, demo_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
