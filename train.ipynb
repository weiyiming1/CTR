{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.feature_size = cfg['feature_size']\n",
    "        self.field_size = cfg['field_size']\n",
    "        self.embed_size = cfg['embed_size']\n",
    "        self.dropout_fm = cfg['dropout_fm']\n",
    "        self.deep_nn = cfg['deep_layers']\n",
    "        self.dropout_deep = cfg['dropout_deep']\n",
    "        \n",
    "        self.w_feature_embed = tf.Variable(tf.random.normal(shape=[cfg['feature_size'], cfg['embed_size']], mean=0.0, stddev=0.01))\n",
    "        self.w_feature_bias = tf.Variable(tf.random.normal(shape=[cfg['feature_size'], 1], mean=0.0, stddev=0.01))\n",
    "        self.initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.deep_w = dict()\n",
    "        self.deep_b = dict()\n",
    "\n",
    "    def __call__(self, feature_idx, feature_val)\n",
    "        reshaped_feature_val = tf.reshape(feature_val, shape=[-1,self.field_size,1])\n",
    "        # fm\n",
    "        first_order = tf.nn.embedding_lookup(self.w_feature_bias,feature_idx)\n",
    "        fm_first_order = tf.reduce_sum(tf.multiply(first_order,reshaped_feature_val),2)\n",
    "\n",
    "        embeddings = tf.nn.embedding_lookup(self.w_feature_embed,feature_idx)\n",
    "        second_inner = tf.multiply(embeddings,reshaped_feature_val)\n",
    "        \n",
    "        summed_features_emb = tf.reduce_sum(second_inner,1)\n",
    "        summed_features_emb_square = tf.square(summed_features_emb)\n",
    "        summed_features_emb_square.shape\n",
    "        \n",
    "        squared_features_emb = tf.square(second_inner)\n",
    "        squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "        squared_sum_features_emb.shape\n",
    "        \n",
    "        fm_second_order = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "        \n",
    "        # dnn\n",
    "        y_deep = tf.reshape(embeddings,shape=[-1,self.field_size * self.embed_size])\n",
    "        for layer in range(0, len(self.deep_nn)):\n",
    "            if layer==0:\n",
    "                input_size = self.field_size * self.embed_size\n",
    "                deep_w[layer] = tf.Variable(self.initializer([input_size, self.deep_nn[0]]))\n",
    "            else:    \n",
    "                deep_w[layer] = tf.Variable(self.initializer([self.deep_nn[layer-1], self.deep_nn[layer]]))\n",
    "\n",
    "            deep_b[layer] = tf.Variable(initializer([1, self.deep_nn[layer]]))\n",
    "\n",
    "            y_deep = tf.add(tf.matmul(y_deep, deep_w[layer]), deep_b[layer])\n",
    "            y_deep = tf.nn.relu(y_deep)\n",
    "        \n",
    "        # concat\n",
    "        concat = tf.concat([fm_first_order,fm_second_order,y_deep],axis=1)                        \n",
    "        concat_w = tf.Variable(initializer([concat.shape[1], 1]))\n",
    "        concat_b = tf.Variable(0.01)\n",
    "        \n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(concat,concat_w),concat_b))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x_idx, x_val, y):\n",
    "    y_ = model(x_idx, x_val)\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return loss_object(y_true=y, y_pred=y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, x_idx, x_val, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_val = loss(model, x_idx, x_val, labels)\n",
    "    return loss_value, tape.gradient(loss_val, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_index = tf.constant(feature_idx[:3].values)\n",
    "demo_val = tf.constant(feature_val[:3].values, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, grads = grad(model, demo_index, demo_val, labels)\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(), loss_value.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
