{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./train.csv\"\n",
    "test_file = \"./test.csv\"\n",
    "num_cols = [\"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\"]\n",
    "ignore_cols = [\"id\", \"target\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \n",
    "               \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \n",
    "               \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\",\"ps_calc_15_bin\", \"ps_calc_16_bin\", \n",
    "               \"ps_calc_17_bin\",\"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview():    \n",
    "    dfTrain = pd.read_csv(train_file)\n",
    "    dfTest = pd.read_csv(test_file)\n",
    "    df = pd.concat([dfTrain,dfTest], sort=False)\n",
    "\n",
    "    field_size = len(df.columns) - len(ignore_cols)\n",
    "    feature_dict = {}\n",
    "    feature_size = 0\n",
    "    for col in df.columns:\n",
    "        if col in ignore_cols:\n",
    "            continue\n",
    "        elif col in num_cols:\n",
    "            feature_dict[col] = feature_size\n",
    "            feature_size += 1\n",
    "        else:\n",
    "            unique_val = df[col].unique()\n",
    "            feature_dict[col] = dict(zip(unique_val,range(feature_size,len(unique_val) + feature_size)))\n",
    "            feature_size += len(unique_val)\n",
    "    return dfTrain, field_size, feature_size, feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, split):\n",
    "    label_df = train_df[['target']]\n",
    "    train_df.drop(['target','id'],axis=1,inplace=True)\n",
    "    feature_idx = train_df.copy()\n",
    "    feature_val = train_df.copy()\n",
    "    for col in feature_idx.columns:\n",
    "        if col in ignore_cols:\n",
    "            feature_idx.drop(col,axis=1,inplace=True)\n",
    "            feature_val.drop(col,axis=1,inplace=True)\n",
    "            continue\n",
    "        elif col in num_cols:\n",
    "            feature_idx[col] = feature_dict[col]\n",
    "        else:\n",
    "            feature_idx[col] = feature_idx[col].map(feature_dict[col])\n",
    "            feature_val[col] = 1        \n",
    "            \n",
    "    split_idx = feature_idx.shape[0] - round(feature_idx.shape[0]*split)\n",
    "    train_input = [feature_idx[:split_idx].values, feature_val[:split_idx].values]\n",
    "    train_y = label_df[:split_idx].values\n",
    "    validate_input = [feature_idx[split_idx:].values, feature_val[split_idx:].values]\n",
    "    validate_y = label_df[split_idx:].values\n",
    "\n",
    "    return train_input, train_y, validate_input, validate_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain, field_size, feature_size, feature_dict = overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_y, validate_input, validate_y = preprocess(dfTrain, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(tf.keras.Model):\n",
    "    def __init__(self, cfg):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.feature_size = cfg['feature_size']\n",
    "        self.field_size = cfg['field_size']\n",
    "        self.embed_size = cfg['embed_size']\n",
    "        self.deep_nn = cfg['deep_nn']\n",
    "        \n",
    "        self.dropout_fm = cfg['dropout_fm']\n",
    "        self.dropout_deep = cfg['dropout_deep']\n",
    "        \n",
    "        # fm        \n",
    "        self.feature_weight = tf.keras.layers.Embedding(cfg['feature_size'], 1)\n",
    "        self.feature_embed = tf.keras.layers.Embedding(cfg['feature_size'], cfg['embed_size'])\n",
    "\n",
    "        # dnn\n",
    "        for layer in range(len(cfg['deep_nn'])):\n",
    "            setattr(self, 'dense_' + str(layer), tf.keras.layers.Dense(self.deep_nn[layer]))\n",
    "            setattr(self, 'batchNorm_' + str(layer), tf.keras.layers.BatchNormalization())\n",
    "            setattr(self, 'activation_' + str(layer), tf.keras.layers.Activation('relu'))\n",
    "            setattr(self, 'dropout_' + str(layer), tf.keras.layers.Dropout(self.dropout_deep))\n",
    "            \n",
    "        self.fc = tf.keras.layers.Dense(1, activation='sigmoid', use_bias=True)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs = [feature_idx, feature_val]\n",
    "        reshaped_feature_val = tf.cast(tf.reshape(inputs[1], shape=[-1,self.field_size,1]), tf.float32)\n",
    "        # linear        \n",
    "        weights = self.feature_weight(inputs[0])\n",
    "        linear = tf.reduce_sum(tf.multiply(weights,reshaped_feature_val),2)\n",
    "        \n",
    "        # fm  \n",
    "        embeddings = self.feature_embed(inputs[0])\n",
    "        second_inner = tf.multiply(embeddings,reshaped_feature_val)\n",
    "        \n",
    "        summed_features_emb = tf.reduce_sum(second_inner,1)\n",
    "        summed_features_emb_square = tf.square(summed_features_emb)\n",
    "        \n",
    "        squared_features_emb = tf.square(second_inner)\n",
    "        squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "        \n",
    "        fm = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "        \n",
    "        # dnn\n",
    "        y_deep = tf.reshape(embeddings,shape=[-1,self.field_size * self.embed_size])\n",
    "        for layer in range(0, len(self.deep_nn)):\n",
    "            y_deep = getattr(self, 'dense_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'batchNorm_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'activation_' + str(layer))(y_deep)\n",
    "            y_deep = getattr(self, 'dropout_' + str(layer))(y_deep)\n",
    "            \n",
    "        # concat\n",
    "        concat = tf.concat([linear, fm, y_deep], axis=1)                                \n",
    "        out = self.fc(concat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"feature_size\": feature_size,\n",
    "    \"field_size\": field_size,\n",
    "    \"embed_size\":8,\n",
    "    \"deep_nn\":[32,32],\n",
    "    \"dropout_fm\": 0,\n",
    "    \"dropout_deep\": 0.2,\n",
    "    \"epoch\":20,\n",
    "    \"batch\":10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 535691 samples, validate on 59521 samples\n",
      "Epoch 1/20\n",
      "535691/535691 [==============================] - 3s 5us/sample - loss: 0.3255 - binary_accuracy: 0.9190 - AUC: 0.5123 - val_loss: 0.2037 - val_binary_accuracy: 0.9633 - val_AUC: 0.4658\n",
      "Epoch 2/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1586 - binary_accuracy: 0.9636 - AUC: 0.5566 - val_loss: 0.1654 - val_binary_accuracy: 0.9633 - val_AUC: 0.5009\n",
      "Epoch 3/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1568 - binary_accuracy: 0.9636 - AUC: 0.5815 - val_loss: 0.1608 - val_binary_accuracy: 0.9633 - val_AUC: 0.5217\n",
      "Epoch 4/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1557 - binary_accuracy: 0.9636 - AUC: 0.5970 - val_loss: 0.1586 - val_binary_accuracy: 0.9633 - val_AUC: 0.5433\n",
      "Epoch 5/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1553 - binary_accuracy: 0.9636 - AUC: 0.6002 - val_loss: 0.1571 - val_binary_accuracy: 0.9633 - val_AUC: 0.5672\n",
      "Epoch 6/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1547 - binary_accuracy: 0.9636 - AUC: 0.6095 - val_loss: 0.1566 - val_binary_accuracy: 0.9633 - val_AUC: 0.5803\n",
      "Epoch 7/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1543 - binary_accuracy: 0.9636 - AUC: 0.6121 - val_loss: 0.1558 - val_binary_accuracy: 0.9633 - val_AUC: 0.5918\n",
      "Epoch 8/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1541 - binary_accuracy: 0.9636 - AUC: 0.6152 - val_loss: 0.1554 - val_binary_accuracy: 0.9633 - val_AUC: 0.6059\n",
      "Epoch 9/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1538 - binary_accuracy: 0.9636 - AUC: 0.6195 - val_loss: 0.1546 - val_binary_accuracy: 0.9633 - val_AUC: 0.6142\n",
      "Epoch 10/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1535 - binary_accuracy: 0.9636 - AUC: 0.6221 - val_loss: 0.1542 - val_binary_accuracy: 0.9633 - val_AUC: 0.6194\n",
      "Epoch 11/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1535 - binary_accuracy: 0.9636 - AUC: 0.6221 - val_loss: 0.1539 - val_binary_accuracy: 0.9633 - val_AUC: 0.6230\n",
      "Epoch 12/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1531 - binary_accuracy: 0.9636 - AUC: 0.6275 - val_loss: 0.1538 - val_binary_accuracy: 0.9633 - val_AUC: 0.6262\n",
      "Epoch 13/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1530 - binary_accuracy: 0.9636 - AUC: 0.6279 - val_loss: 0.1541 - val_binary_accuracy: 0.9633 - val_AUC: 0.6232\n",
      "Epoch 14/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1528 - binary_accuracy: 0.9636 - AUC: 0.6297 - val_loss: 0.1536 - val_binary_accuracy: 0.9633 - val_AUC: 0.6241\n",
      "Epoch 15/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1529 - binary_accuracy: 0.9636 - AUC: 0.6280 - val_loss: 0.1535 - val_binary_accuracy: 0.9633 - val_AUC: 0.6276\n",
      "Epoch 16/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1526 - binary_accuracy: 0.9636 - AUC: 0.6334 - val_loss: 0.1534 - val_binary_accuracy: 0.9633 - val_AUC: 0.6274\n",
      "Epoch 17/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1524 - binary_accuracy: 0.9636 - AUC: 0.6353 - val_loss: 0.1535 - val_binary_accuracy: 0.9633 - val_AUC: 0.6269\n",
      "Epoch 18/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1523 - binary_accuracy: 0.9636 - AUC: 0.6365 - val_loss: 0.1535 - val_binary_accuracy: 0.9633 - val_AUC: 0.6269\n",
      "Epoch 19/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1523 - binary_accuracy: 0.9636 - AUC: 0.6359 - val_loss: 0.1534 - val_binary_accuracy: 0.9633 - val_AUC: 0.6274\n",
      "Epoch 20/20\n",
      "535691/535691 [==============================] - 1s 2us/sample - loss: 0.1522 - binary_accuracy: 0.9636 - AUC: 0.6367 - val_loss: 0.1534 - val_binary_accuracy: 0.9633 - val_AUC: 0.6276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda7bb1da58>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepFM(cfg)\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['binary_accuracy', 'AUC'])\n",
    "model.fit(train_input, train_y, epochs=cfg['epoch'], batch_size=cfg['batch'], shuffle=True,\n",
    "          verbose=1, validation_data=(validate_input, validate_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepredict(path):\n",
    "    predict_df = pd.read_csv(path)\n",
    "    feature_idx = predict_df.copy()\n",
    "    feature_val = predict_df.copy()\n",
    "    for col in feature_idx.columns:\n",
    "        if col in ignore_cols:\n",
    "            feature_idx.drop(col,axis=1,inplace=True)\n",
    "            feature_val.drop(col,axis=1,inplace=True)\n",
    "            continue\n",
    "        elif col in num_cols:\n",
    "            feature_idx[col] = feature_dict[col]\n",
    "        else:\n",
    "            feature_idx[col] = feature_idx[col].map(feature_dict[col])\n",
    "            feature_val[col] = 1 \n",
    "    return [feature_idx.values, feature_val.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = prepredict(test_file)\n",
    "label_pre = model.predict(predict_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02657855],\n",
       "       [0.03356069],\n",
       "       [0.03306636],\n",
       "       ...,\n",
       "       [0.05187541],\n",
       "       [0.03323221],\n",
       "       [0.0299944 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(-label_pre, axis=0)\n",
    "sorted_val = label_pre[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5062654 ]],\n",
       "\n",
       "       [[0.5047808 ]],\n",
       "\n",
       "       [[0.5031859 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00576538]],\n",
       "\n",
       "       [[0.00562268]],\n",
       "\n",
       "       [[0.00548503]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pre_for_train = model.predict(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.037514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.044497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.038351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.031306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.037130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.050614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.029751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.060178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.025806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.020296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.032817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.057369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.023245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.018018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.028497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.031835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.050538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.032378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.044405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.034941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.028306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.051580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.034179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.059864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.020363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.041436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.020366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.059662\n",
       "1   0.025427\n",
       "2   0.020657\n",
       "3   0.014821\n",
       "4   0.037768\n",
       "5   0.038043\n",
       "6   0.021303\n",
       "7   0.010496\n",
       "8   0.029850\n",
       "9   0.059881\n",
       "10  0.037514\n",
       "11  0.044497\n",
       "12  0.038351\n",
       "13  0.031306\n",
       "14  0.037130\n",
       "15  0.050614\n",
       "16  0.029751\n",
       "17  0.060178\n",
       "18  0.007198\n",
       "19  0.025806\n",
       "20  0.020296\n",
       "21  0.032817\n",
       "22  0.057369\n",
       "23  0.023245\n",
       "24  0.018090\n",
       "25  0.018018\n",
       "26  0.028497\n",
       "27  0.031835\n",
       "28  0.050538\n",
       "29  0.032378\n",
       "30  0.044405\n",
       "31  0.034941\n",
       "32  0.028306\n",
       "33  0.031605\n",
       "34  0.051580\n",
       "35  0.034179\n",
       "36  0.059864\n",
       "37  0.020363\n",
       "38  0.041436\n",
       "39  0.020366"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pre_for_train_pd = pd.DataFrame(label_pre_for_train)\n",
    "label_pre_for_train_pd.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   0\n",
       "1   0\n",
       "2   0\n",
       "3   0\n",
       "4   0\n",
       "5   0\n",
       "6   0\n",
       "7   0\n",
       "8   0\n",
       "9   1\n",
       "10  0\n",
       "11  0\n",
       "12  0\n",
       "13  0\n",
       "14  0\n",
       "15  0\n",
       "16  0\n",
       "17  0\n",
       "18  0\n",
       "19  1\n",
       "20  0\n",
       "21  0\n",
       "22  0\n",
       "23  0\n",
       "24  0\n",
       "25  0\n",
       "26  0\n",
       "27  0\n",
       "28  1\n",
       "29  0\n",
       "30  0\n",
       "31  0\n",
       "32  0\n",
       "33  0\n",
       "34  0\n",
       "35  0\n",
       "36  0\n",
       "37  0\n",
       "38  0\n",
       "39  1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_pd = pd.DataFrame(train_y)\n",
    "train_y_pd.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
